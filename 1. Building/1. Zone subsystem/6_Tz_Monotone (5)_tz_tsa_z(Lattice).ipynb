{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pYcTCRwIJASl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_lattice as tfl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DATA\n",
        "df = pd.read_csv('C:/Users/tln229/Downloads/Python/Building/data/HVAC_B90_102_exp_10m_20210424.csv')\n",
        "\n",
        "n_train = 128\n",
        "\n",
        "# trainning set\n",
        "Tz_k   = np.array(df['room_temp']).reshape(-1,1)[0: n_train]\n",
        "Tsa_k1 = np.array(df['supply_discharge_temp']).reshape(-1,1)[1: n_train+1]\n",
        "msa_k1 = np.array(df['airflow_current']).reshape(-1,1)[1: n_train+1]\n",
        "z      = ((msa_k1-400)/600)*(Tsa_k1-Tz_k)\n",
        "Tz_k1  = np.array(df['room_temp']).reshape(-1,1)[1: n_train+1]\n",
        "\n",
        "X = np.concatenate((Tz_k, (Tsa_k1-65)/20, z), axis=1)\n",
        "Y = np.copy(Tz_k1)\n",
        "\n",
        "# test set\n",
        "Tz_k_t   = np.array(df['room_temp']).reshape(-1,1)[n_train: 1600]\n",
        "Tsa_k1_t = np.array(df['supply_discharge_temp']).reshape(-1,1)[n_train+1: 1600+1]\n",
        "msa_k1_t = np.array(df['airflow_current']).reshape(-1,1)[n_train+1: 1600+1]\n",
        "z_t      = ((msa_k1_t-400)/600)*(Tsa_k1_t-Tz_k_t)\n",
        "Tz_k1_t  = np.array(df['room_temp']).reshape(-1,1)[n_train+1: 1600+1]\n",
        "\n",
        "X_t = np.concatenate((Tz_k_t, (Tsa_k1_t-65)/20, z_t), axis=1)\n",
        "Y_t = np.copy(Tz_k1_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bj-5YGugJs5l"
      },
      "outputs": [],
      "source": [
        "# combined calibrator\n",
        "combined_calibrators = tfl.layers.ParallelCombination()\n",
        "\n",
        "calibrator_x1 = tfl.layers.PWLCalibration(input_keypoints=np.linspace(65,85,10), output_min=0, output_max=2)\n",
        "calibrator_x2 = tfl.layers.PWLCalibration(input_keypoints=np.linspace(-1,2,10), output_min=0, output_max=2, monotonicity='increasing')\n",
        "calibrator_x3 = tfl.layers.PWLCalibration(input_keypoints=np.linspace(-1,20,10), output_min=0, output_max=2, monotonicity='increasing')\n",
        "\n",
        "combined_calibrators.append(calibrator_x1)\n",
        "combined_calibrators.append(calibrator_x2)\n",
        "combined_calibrators.append(calibrator_x3)\n",
        "\n",
        "# Lattice\n",
        "lattice = tfl.layers.Lattice(\n",
        "    lattice_sizes = [3, 3, 3],\n",
        "    monotonicities = ['increasing', 'increasing', 'increasing'],\n",
        "    output_min = 65,\n",
        "    output_max = 85)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4MWFZnolMiuz"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(combined_calibrators)\n",
        "model.add(lattice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQxWZe6rMjPb",
        "outputId": "467a0702-c216-4b35-c319-fc3ef1132da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20000\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 6.7659 - r_square: -1.2335 - val_loss: 5.4396 - val_r_square: -0.6008\n",
            "Epoch 2/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.1579 - r_square: -0.7027 - val_loss: 4.7645 - val_r_square: -0.4021\n",
            "Epoch 3/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.9808 - r_square: -0.3141 - val_loss: 4.3995 - val_r_square: -0.2947\n",
            "Epoch 4/20000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.2210 - r_square: -0.0633 - val_loss: 4.2983 - val_r_square: -0.2649\n",
            "Epoch 5/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8316 - r_square: 0.0653 - val_loss: 4.3794 - val_r_square: -0.2888\n",
            "Epoch 6/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7241 - r_square: 0.1007 - val_loss: 4.5366 - val_r_square: -0.3350\n",
            "Epoch 7/20000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7785 - r_square: 0.0828 - val_loss: 4.6696 - val_r_square: -0.3742\n",
            "Epoch 8/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8744 - r_square: 0.0511 - val_loss: 4.7123 - val_r_square: -0.3867\n",
            "Epoch 9/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.9252 - r_square: 0.0344 - val_loss: 4.6231 - val_r_square: -0.3605\n",
            "Epoch 10/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.8779 - r_square: 0.0500 - val_loss: 4.4020 - val_r_square: -0.2954\n",
            "Epoch 11/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7244 - r_square: 0.1007 - val_loss: 4.0875 - val_r_square: -0.2029\n",
            "Epoch 12/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4962 - r_square: 0.1760 - val_loss: 3.7246 - val_r_square: -0.0961\n",
            "Epoch 13/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2351 - r_square: 0.2622 - val_loss: 3.3545 - val_r_square: 0.0128\n",
            "Epoch 14/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.9806 - r_square: 0.3462 - val_loss: 3.0098 - val_r_square: 0.1143\n",
            "Epoch 15/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7630 - r_square: 0.4180 - val_loss: 2.7116 - val_r_square: 0.2020\n",
            "Epoch 16/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5993 - r_square: 0.4721 - val_loss: 2.4684 - val_r_square: 0.2736\n",
            "Epoch 17/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4920 - r_square: 0.5075 - val_loss: 2.2779 - val_r_square: 0.3297\n",
            "Epoch 18/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4311 - r_square: 0.5276 - val_loss: 2.1293 - val_r_square: 0.3734\n",
            "Epoch 19/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3982 - r_square: 0.5384 - val_loss: 2.0083 - val_r_square: 0.4090\n",
            "Epoch 20/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3718 - r_square: 0.5472 - val_loss: 1.9014 - val_r_square: 0.4404\n",
            "Epoch 21/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3341 - r_square: 0.5596 - val_loss: 1.7996 - val_r_square: 0.4704\n",
            "Epoch 22/20000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.2747 - r_square: 0.5792 - val_loss: 1.6998 - val_r_square: 0.4998\n",
            "Epoch 23/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1923 - r_square: 0.6064 - val_loss: 1.6037 - val_r_square: 0.5281\n",
            "Epoch 24/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0933 - r_square: 0.6391 - val_loss: 1.5163 - val_r_square: 0.5538\n",
            "Epoch 25/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9884 - r_square: 0.6737 - val_loss: 1.4427 - val_r_square: 0.5755\n",
            "Epoch 26/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8892 - r_square: 0.7065 - val_loss: 1.3871 - val_r_square: 0.5918\n",
            "Epoch 27/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8062 - r_square: 0.7339 - val_loss: 1.3511 - val_r_square: 0.6024\n",
            "Epoch 28/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7464 - r_square: 0.7536 - val_loss: 1.3315 - val_r_square: 0.6081\n",
            "Epoch 29/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7113 - r_square: 0.7652 - val_loss: 1.3166 - val_r_square: 0.6126\n",
            "Epoch 30/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6895 - r_square: 0.7724 - val_loss: 1.2986 - val_r_square: 0.6178\n",
            "Epoch 31/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6730 - r_square: 0.7778 - val_loss: 1.2722 - val_r_square: 0.6256\n",
            "Epoch 32/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6561 - r_square: 0.7834 - val_loss: 1.2339 - val_r_square: 0.6369\n",
            "Epoch 33/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6347 - r_square: 0.7905 - val_loss: 1.1830 - val_r_square: 0.6519\n",
            "Epoch 34/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6076 - r_square: 0.7994 - val_loss: 1.1217 - val_r_square: 0.6699\n",
            "Epoch 35/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5759 - r_square: 0.8099 - val_loss: 1.0545 - val_r_square: 0.6897\n",
            "Epoch 36/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5421 - r_square: 0.8210 - val_loss: 0.9864 - val_r_square: 0.7097\n",
            "Epoch 37/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5098 - r_square: 0.8317 - val_loss: 0.9216 - val_r_square: 0.7288\n",
            "Epoch 38/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4819 - r_square: 0.8409 - val_loss: 0.8633 - val_r_square: 0.7459\n",
            "Epoch 39/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4597 - r_square: 0.8482 - val_loss: 0.8129 - val_r_square: 0.7608\n",
            "Epoch 40/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4432 - r_square: 0.8537 - val_loss: 0.7701 - val_r_square: 0.7734\n",
            "Epoch 41/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4306 - r_square: 0.8579 - val_loss: 0.7340 - val_r_square: 0.7840\n",
            "Epoch 42/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4195 - r_square: 0.8615 - val_loss: 0.7030 - val_r_square: 0.7931\n",
            "Epoch 43/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4078 - r_square: 0.8654 - val_loss: 0.6758 - val_r_square: 0.8011\n",
            "Epoch 44/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3938 - r_square: 0.8700 - val_loss: 0.6516 - val_r_square: 0.8082\n",
            "Epoch 45/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3774 - r_square: 0.8754 - val_loss: 0.6303 - val_r_square: 0.8145\n",
            "Epoch 46/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3592 - r_square: 0.8814 - val_loss: 0.6117 - val_r_square: 0.8200\n",
            "Epoch 47/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3405 - r_square: 0.8876 - val_loss: 0.5961 - val_r_square: 0.8246\n",
            "Epoch 48/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3229 - r_square: 0.8934 - val_loss: 0.5832 - val_r_square: 0.8284\n",
            "Epoch 49/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3077 - r_square: 0.8984 - val_loss: 0.5726 - val_r_square: 0.8315\n",
            "Epoch 50/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2961 - r_square: 0.9023 - val_loss: 0.5623 - val_r_square: 0.8345\n",
            "Epoch 51/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2859 - r_square: 0.9056 - val_loss: 0.5514 - val_r_square: 0.8377\n",
            "Epoch 52/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2765 - r_square: 0.9087 - val_loss: 0.5389 - val_r_square: 0.8414\n",
            "Epoch 53/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2674 - r_square: 0.9117 - val_loss: 0.5245 - val_r_square: 0.8457\n",
            "Epoch 54/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2580 - r_square: 0.9148 - val_loss: 0.5079 - val_r_square: 0.8505\n",
            "Epoch 55/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2482 - r_square: 0.9181 - val_loss: 0.4897 - val_r_square: 0.8559\n",
            "Epoch 56/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2381 - r_square: 0.9214 - val_loss: 0.4704 - val_r_square: 0.8616\n",
            "Epoch 57/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2279 - r_square: 0.9248 - val_loss: 0.4509 - val_r_square: 0.8673\n",
            "Epoch 58/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2181 - r_square: 0.9280 - val_loss: 0.4320 - val_r_square: 0.8729\n",
            "Epoch 59/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2091 - r_square: 0.9310 - val_loss: 0.4142 - val_r_square: 0.8781\n",
            "Epoch 60/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2008 - r_square: 0.9337 - val_loss: 0.3980 - val_r_square: 0.8829\n",
            "Epoch 61/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1933 - r_square: 0.9362 - val_loss: 0.3833 - val_r_square: 0.8872\n",
            "Epoch 62/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1863 - r_square: 0.9385 - val_loss: 0.3703 - val_r_square: 0.8910\n",
            "Epoch 63/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1794 - r_square: 0.9408 - val_loss: 0.3587 - val_r_square: 0.8944\n",
            "Epoch 64/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1726 - r_square: 0.9430 - val_loss: 0.3484 - val_r_square: 0.8975\n",
            "Epoch 65/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1656 - r_square: 0.9453 - val_loss: 0.3393 - val_r_square: 0.9001\n",
            "Epoch 66/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1587 - r_square: 0.9476 - val_loss: 0.3312 - val_r_square: 0.9025\n",
            "Epoch 67/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1519 - r_square: 0.9498 - val_loss: 0.3242 - val_r_square: 0.9046\n",
            "Epoch 68/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1457 - r_square: 0.9519 - val_loss: 0.3178 - val_r_square: 0.9065\n",
            "Epoch 69/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1399 - r_square: 0.9538 - val_loss: 0.3117 - val_r_square: 0.9083\n",
            "Epoch 70/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1345 - r_square: 0.9556 - val_loss: 0.3056 - val_r_square: 0.9101\n",
            "Epoch 71/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1293 - r_square: 0.9573 - val_loss: 0.2995 - val_r_square: 0.9119\n",
            "Epoch 72/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1245 - r_square: 0.9589 - val_loss: 0.2930 - val_r_square: 0.9138\n",
            "Epoch 73/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1198 - r_square: 0.9605 - val_loss: 0.2861 - val_r_square: 0.9158\n",
            "Epoch 74/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1152 - r_square: 0.9620 - val_loss: 0.2789 - val_r_square: 0.9179\n",
            "Epoch 75/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1108 - r_square: 0.9634 - val_loss: 0.2714 - val_r_square: 0.9201\n",
            "Epoch 76/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1065 - r_square: 0.9648 - val_loss: 0.2638 - val_r_square: 0.9224\n",
            "Epoch 77/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1024 - r_square: 0.9662 - val_loss: 0.2566 - val_r_square: 0.9245\n",
            "Epoch 78/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0986 - r_square: 0.9675 - val_loss: 0.2496 - val_r_square: 0.9265\n",
            "Epoch 79/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0950 - r_square: 0.9686 - val_loss: 0.2429 - val_r_square: 0.9285\n",
            "Epoch 80/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0916 - r_square: 0.9698 - val_loss: 0.2366 - val_r_square: 0.9304\n",
            "Epoch 81/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0884 - r_square: 0.9708 - val_loss: 0.2308 - val_r_square: 0.9321\n",
            "Epoch 82/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0853 - r_square: 0.9719 - val_loss: 0.2253 - val_r_square: 0.9337\n",
            "Epoch 83/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0823 - r_square: 0.9728 - val_loss: 0.2203 - val_r_square: 0.9352\n",
            "Epoch 84/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0794 - r_square: 0.9738 - val_loss: 0.2157 - val_r_square: 0.9365\n",
            "Epoch 85/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0766 - r_square: 0.9747 - val_loss: 0.2114 - val_r_square: 0.9378\n",
            "Epoch 86/20000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0739 - r_square: 0.9756 - val_loss: 0.2074 - val_r_square: 0.9390\n",
            "Epoch 87/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0714 - r_square: 0.9764 - val_loss: 0.2035 - val_r_square: 0.9401\n",
            "Epoch 88/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0690 - r_square: 0.9772 - val_loss: 0.1996 - val_r_square: 0.9413\n",
            "Epoch 89/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0667 - r_square: 0.9780 - val_loss: 0.1957 - val_r_square: 0.9424\n",
            "Epoch 90/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0645 - r_square: 0.9787 - val_loss: 0.1917 - val_r_square: 0.9436\n",
            "Epoch 91/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0624 - r_square: 0.9794 - val_loss: 0.1875 - val_r_square: 0.9448\n",
            "Epoch 92/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0604 - r_square: 0.9800 - val_loss: 0.1832 - val_r_square: 0.9461\n",
            "Epoch 93/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0585 - r_square: 0.9807 - val_loss: 0.1788 - val_r_square: 0.9474\n",
            "Epoch 94/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0567 - r_square: 0.9813 - val_loss: 0.1744 - val_r_square: 0.9487\n",
            "Epoch 95/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0549 - r_square: 0.9819 - val_loss: 0.1700 - val_r_square: 0.9500\n",
            "Epoch 96/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0532 - r_square: 0.9824 - val_loss: 0.1657 - val_r_square: 0.9512\n",
            "Epoch 97/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0517 - r_square: 0.9829 - val_loss: 0.1617 - val_r_square: 0.9524\n",
            "Epoch 98/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0501 - r_square: 0.9834 - val_loss: 0.1579 - val_r_square: 0.9535\n",
            "Epoch 99/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0487 - r_square: 0.9839 - val_loss: 0.1543 - val_r_square: 0.9546\n",
            "Epoch 100/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - r_square: 0.9844 - val_loss: 0.1510 - val_r_square: 0.9556\n",
            "Epoch 101/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0460 - r_square: 0.9848 - val_loss: 0.1478 - val_r_square: 0.9565\n",
            "Epoch 102/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0447 - r_square: 0.9852 - val_loss: 0.1449 - val_r_square: 0.9574\n",
            "Epoch 103/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0435 - r_square: 0.9857 - val_loss: 0.1421 - val_r_square: 0.9582\n",
            "Epoch 104/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0423 - r_square: 0.9860 - val_loss: 0.1394 - val_r_square: 0.9590\n",
            "Epoch 105/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0412 - r_square: 0.9864 - val_loss: 0.1367 - val_r_square: 0.9598\n",
            "Epoch 106/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0401 - r_square: 0.9868 - val_loss: 0.1340 - val_r_square: 0.9606\n",
            "Epoch 107/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0391 - r_square: 0.9871 - val_loss: 0.1313 - val_r_square: 0.9614\n",
            "Epoch 108/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0381 - r_square: 0.9874 - val_loss: 0.1286 - val_r_square: 0.9622\n",
            "Epoch 109/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0371 - r_square: 0.9877 - val_loss: 0.1258 - val_r_square: 0.9630\n",
            "Epoch 110/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0362 - r_square: 0.9880 - val_loss: 0.1231 - val_r_square: 0.9638\n",
            "Epoch 111/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0354 - r_square: 0.9883 - val_loss: 0.1204 - val_r_square: 0.9646\n",
            "Epoch 112/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0345 - r_square: 0.9886 - val_loss: 0.1178 - val_r_square: 0.9653\n",
            "Epoch 113/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0337 - r_square: 0.9889 - val_loss: 0.1152 - val_r_square: 0.9661\n",
            "Epoch 114/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0329 - r_square: 0.9891 - val_loss: 0.1128 - val_r_square: 0.9668\n",
            "Epoch 115/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0322 - r_square: 0.9894 - val_loss: 0.1106 - val_r_square: 0.9675\n",
            "Epoch 116/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0315 - r_square: 0.9896 - val_loss: 0.1085 - val_r_square: 0.9681\n",
            "Epoch 117/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0308 - r_square: 0.9898 - val_loss: 0.1065 - val_r_square: 0.9687\n",
            "Epoch 118/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0301 - r_square: 0.9901 - val_loss: 0.1046 - val_r_square: 0.9692\n",
            "Epoch 119/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0295 - r_square: 0.9903 - val_loss: 0.1029 - val_r_square: 0.9697\n",
            "Epoch 120/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0289 - r_square: 0.9905 - val_loss: 0.1012 - val_r_square: 0.9702\n",
            "Epoch 121/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0283 - r_square: 0.9907 - val_loss: 0.0995 - val_r_square: 0.9707\n",
            "Epoch 122/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0277 - r_square: 0.9909 - val_loss: 0.0979 - val_r_square: 0.9712\n",
            "Epoch 123/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0271 - r_square: 0.9910 - val_loss: 0.0963 - val_r_square: 0.9717\n",
            "Epoch 124/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0266 - r_square: 0.9912 - val_loss: 0.0945 - val_r_square: 0.9722\n",
            "Epoch 125/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0261 - r_square: 0.9914 - val_loss: 0.0927 - val_r_square: 0.9727\n",
            "Epoch 126/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0257 - r_square: 0.9915 - val_loss: 0.0911 - val_r_square: 0.9732\n",
            "Epoch 127/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0253 - r_square: 0.9917 - val_loss: 0.0897 - val_r_square: 0.9736\n",
            "Epoch 128/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0248 - r_square: 0.9918 - val_loss: 0.0884 - val_r_square: 0.9740\n",
            "Epoch 129/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0244 - r_square: 0.9919 - val_loss: 0.0873 - val_r_square: 0.9743\n",
            "Epoch 130/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0240 - r_square: 0.9921 - val_loss: 0.0863 - val_r_square: 0.9746\n",
            "Epoch 131/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0236 - r_square: 0.9922 - val_loss: 0.0853 - val_r_square: 0.9749\n",
            "Epoch 132/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0233 - r_square: 0.9923 - val_loss: 0.0842 - val_r_square: 0.9752\n",
            "Epoch 133/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0230 - r_square: 0.9924 - val_loss: 0.0833 - val_r_square: 0.9755\n",
            "Epoch 134/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0227 - r_square: 0.9925 - val_loss: 0.0825 - val_r_square: 0.9757\n",
            "Epoch 135/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0224 - r_square: 0.9926 - val_loss: 0.0818 - val_r_square: 0.9759\n",
            "Epoch 136/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0221 - r_square: 0.9927 - val_loss: 0.0810 - val_r_square: 0.9761\n",
            "Epoch 137/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0218 - r_square: 0.9928 - val_loss: 0.0804 - val_r_square: 0.9763\n",
            "Epoch 138/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0215 - r_square: 0.9929 - val_loss: 0.0797 - val_r_square: 0.9766\n",
            "Epoch 139/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0212 - r_square: 0.9930 - val_loss: 0.0790 - val_r_square: 0.9768\n",
            "Epoch 140/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0210 - r_square: 0.9931 - val_loss: 0.0782 - val_r_square: 0.9770\n",
            "Epoch 141/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0207 - r_square: 0.9932 - val_loss: 0.0775 - val_r_square: 0.9772\n",
            "Epoch 142/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0204 - r_square: 0.9933 - val_loss: 0.0767 - val_r_square: 0.9774\n",
            "Epoch 143/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0201 - r_square: 0.9934 - val_loss: 0.0759 - val_r_square: 0.9777\n",
            "Epoch 144/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0199 - r_square: 0.9934 - val_loss: 0.0750 - val_r_square: 0.9779\n",
            "Epoch 145/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0196 - r_square: 0.9935 - val_loss: 0.0741 - val_r_square: 0.9782\n",
            "Epoch 146/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0194 - r_square: 0.9936 - val_loss: 0.0733 - val_r_square: 0.9784\n",
            "Epoch 147/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0192 - r_square: 0.9937 - val_loss: 0.0726 - val_r_square: 0.9786\n",
            "Epoch 148/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - r_square: 0.9937 - val_loss: 0.0721 - val_r_square: 0.9788\n",
            "Epoch 149/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0188 - r_square: 0.9938 - val_loss: 0.0717 - val_r_square: 0.9789\n",
            "Epoch 150/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0186 - r_square: 0.9939 - val_loss: 0.0714 - val_r_square: 0.9790\n",
            "Epoch 151/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0184 - r_square: 0.9939 - val_loss: 0.0711 - val_r_square: 0.9791\n",
            "Epoch 152/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0182 - r_square: 0.9940 - val_loss: 0.0708 - val_r_square: 0.9792\n",
            "Epoch 153/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0180 - r_square: 0.9941 - val_loss: 0.0705 - val_r_square: 0.9792\n",
            "Epoch 154/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0178 - r_square: 0.9941 - val_loss: 0.0702 - val_r_square: 0.9793\n",
            "Epoch 155/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0176 - r_square: 0.9942 - val_loss: 0.0698 - val_r_square: 0.9795\n",
            "Epoch 156/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0174 - r_square: 0.9943 - val_loss: 0.0693 - val_r_square: 0.9796\n",
            "Epoch 157/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0172 - r_square: 0.9943 - val_loss: 0.0687 - val_r_square: 0.9798\n",
            "Epoch 158/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0170 - r_square: 0.9944 - val_loss: 0.0681 - val_r_square: 0.9800\n",
            "Epoch 159/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0168 - r_square: 0.9944 - val_loss: 0.0674 - val_r_square: 0.9802\n",
            "Epoch 160/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0166 - r_square: 0.9945 - val_loss: 0.0668 - val_r_square: 0.9803\n",
            "Epoch 161/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0165 - r_square: 0.9946 - val_loss: 0.0662 - val_r_square: 0.9805\n",
            "Epoch 162/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0163 - r_square: 0.9946 - val_loss: 0.0657 - val_r_square: 0.9807\n",
            "Epoch 163/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0161 - r_square: 0.9947 - val_loss: 0.0652 - val_r_square: 0.9808\n",
            "Epoch 164/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0160 - r_square: 0.9947 - val_loss: 0.0648 - val_r_square: 0.9809\n",
            "Epoch 165/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0158 - r_square: 0.9948 - val_loss: 0.0644 - val_r_square: 0.9810\n",
            "Epoch 166/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0156 - r_square: 0.9948 - val_loss: 0.0641 - val_r_square: 0.9812\n",
            "Epoch 167/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0155 - r_square: 0.9949 - val_loss: 0.0637 - val_r_square: 0.9812\n",
            "Epoch 168/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0153 - r_square: 0.9949 - val_loss: 0.0634 - val_r_square: 0.9814\n",
            "Epoch 169/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0151 - r_square: 0.9950 - val_loss: 0.0630 - val_r_square: 0.9815\n",
            "Epoch 170/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0150 - r_square: 0.9950 - val_loss: 0.0626 - val_r_square: 0.9816\n",
            "Epoch 171/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0148 - r_square: 0.9951 - val_loss: 0.0622 - val_r_square: 0.9817\n",
            "Epoch 172/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0147 - r_square: 0.9951 - val_loss: 0.0617 - val_r_square: 0.9818\n",
            "Epoch 173/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0145 - r_square: 0.9952 - val_loss: 0.0613 - val_r_square: 0.9820\n",
            "Epoch 174/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0144 - r_square: 0.9952 - val_loss: 0.0608 - val_r_square: 0.9821\n",
            "Epoch 175/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0143 - r_square: 0.9953 - val_loss: 0.0603 - val_r_square: 0.9823\n",
            "Epoch 176/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0141 - r_square: 0.9953 - val_loss: 0.0598 - val_r_square: 0.9824\n",
            "Epoch 177/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - r_square: 0.9954 - val_loss: 0.0593 - val_r_square: 0.9825\n",
            "Epoch 178/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0138 - r_square: 0.9954 - val_loss: 0.0589 - val_r_square: 0.9827\n",
            "Epoch 179/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0137 - r_square: 0.9955 - val_loss: 0.0585 - val_r_square: 0.9828\n",
            "Epoch 180/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0136 - r_square: 0.9955 - val_loss: 0.0582 - val_r_square: 0.9829\n",
            "Epoch 181/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0135 - r_square: 0.9956 - val_loss: 0.0578 - val_r_square: 0.9830\n",
            "Epoch 182/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0133 - r_square: 0.9956 - val_loss: 0.0575 - val_r_square: 0.9831\n",
            "Epoch 183/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0132 - r_square: 0.9956 - val_loss: 0.0571 - val_r_square: 0.9832\n",
            "Epoch 184/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0131 - r_square: 0.9957 - val_loss: 0.0568 - val_r_square: 0.9833\n",
            "Epoch 185/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0130 - r_square: 0.9957 - val_loss: 0.0564 - val_r_square: 0.9834\n",
            "Epoch 186/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0128 - r_square: 0.9958 - val_loss: 0.0560 - val_r_square: 0.9835\n",
            "Epoch 187/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0127 - r_square: 0.9958 - val_loss: 0.0557 - val_r_square: 0.9836\n",
            "Epoch 188/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0126 - r_square: 0.9958 - val_loss: 0.0553 - val_r_square: 0.9837\n",
            "Epoch 189/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0125 - r_square: 0.9959 - val_loss: 0.0550 - val_r_square: 0.9838\n",
            "Epoch 190/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0124 - r_square: 0.9959 - val_loss: 0.0546 - val_r_square: 0.9839\n",
            "Epoch 191/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0123 - r_square: 0.9959 - val_loss: 0.0543 - val_r_square: 0.9840\n",
            "Epoch 192/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0122 - r_square: 0.9960 - val_loss: 0.0539 - val_r_square: 0.9841\n",
            "Epoch 193/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0121 - r_square: 0.9960 - val_loss: 0.0536 - val_r_square: 0.9842\n",
            "Epoch 194/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0120 - r_square: 0.9961 - val_loss: 0.0533 - val_r_square: 0.9843\n",
            "Epoch 195/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0118 - r_square: 0.9961 - val_loss: 0.0530 - val_r_square: 0.9844\n",
            "Epoch 196/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0117 - r_square: 0.9961 - val_loss: 0.0527 - val_r_square: 0.9845\n",
            "Epoch 197/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0116 - r_square: 0.9962 - val_loss: 0.0524 - val_r_square: 0.9846\n",
            "Epoch 198/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0116 - r_square: 0.9962 - val_loss: 0.0521 - val_r_square: 0.9847\n",
            "Epoch 199/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0115 - r_square: 0.9962 - val_loss: 0.0518 - val_r_square: 0.9848\n",
            "Epoch 200/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0114 - r_square: 0.9962 - val_loss: 0.0515 - val_r_square: 0.9849\n",
            "Epoch 201/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0113 - r_square: 0.9963 - val_loss: 0.0512 - val_r_square: 0.9849\n",
            "Epoch 202/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0112 - r_square: 0.9963 - val_loss: 0.0509 - val_r_square: 0.9850\n",
            "Epoch 203/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0111 - r_square: 0.9963 - val_loss: 0.0506 - val_r_square: 0.9851\n",
            "Epoch 204/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0110 - r_square: 0.9964 - val_loss: 0.0503 - val_r_square: 0.9852\n",
            "Epoch 205/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0109 - r_square: 0.9964 - val_loss: 0.0500 - val_r_square: 0.9853\n",
            "Epoch 206/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0108 - r_square: 0.9964 - val_loss: 0.0497 - val_r_square: 0.9854\n",
            "Epoch 207/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0107 - r_square: 0.9965 - val_loss: 0.0494 - val_r_square: 0.9855\n",
            "Epoch 208/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0107 - r_square: 0.9965 - val_loss: 0.0492 - val_r_square: 0.9855\n",
            "Epoch 209/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0106 - r_square: 0.9965 - val_loss: 0.0489 - val_r_square: 0.9856\n",
            "Epoch 210/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0105 - r_square: 0.9965 - val_loss: 0.0486 - val_r_square: 0.9857\n",
            "Epoch 211/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0104 - r_square: 0.9966 - val_loss: 0.0484 - val_r_square: 0.9858\n",
            "Epoch 212/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0103 - r_square: 0.9966 - val_loss: 0.0481 - val_r_square: 0.9858\n",
            "Epoch 213/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0103 - r_square: 0.9966 - val_loss: 0.0479 - val_r_square: 0.9859\n",
            "Epoch 214/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0102 - r_square: 0.9966 - val_loss: 0.0476 - val_r_square: 0.9860\n",
            "Epoch 215/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0101 - r_square: 0.9967 - val_loss: 0.0474 - val_r_square: 0.9861\n",
            "Epoch 216/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0101 - r_square: 0.9967 - val_loss: 0.0471 - val_r_square: 0.9861\n",
            "Epoch 217/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0100 - r_square: 0.9967 - val_loss: 0.0469 - val_r_square: 0.9862\n",
            "Epoch 218/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0099 - r_square: 0.9967 - val_loss: 0.0467 - val_r_square: 0.9863\n",
            "Epoch 219/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0098 - r_square: 0.9967 - val_loss: 0.0464 - val_r_square: 0.9863\n",
            "Epoch 220/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0098 - r_square: 0.9968 - val_loss: 0.0462 - val_r_square: 0.9864\n",
            "Epoch 221/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0097 - r_square: 0.9968 - val_loss: 0.0460 - val_r_square: 0.9865\n",
            "Epoch 222/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0097 - r_square: 0.9968 - val_loss: 0.0457 - val_r_square: 0.9865\n",
            "Epoch 223/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0096 - r_square: 0.9968 - val_loss: 0.0454 - val_r_square: 0.9866\n",
            "Epoch 224/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0095 - r_square: 0.9969 - val_loss: 0.0452 - val_r_square: 0.9867\n",
            "Epoch 225/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0095 - r_square: 0.9969 - val_loss: 0.0450 - val_r_square: 0.9868\n",
            "Epoch 226/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0094 - r_square: 0.9969 - val_loss: 0.0448 - val_r_square: 0.9868\n",
            "Epoch 227/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0094 - r_square: 0.9969 - val_loss: 0.0447 - val_r_square: 0.9868\n",
            "Epoch 228/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0093 - r_square: 0.9969 - val_loss: 0.0447 - val_r_square: 0.9868\n",
            "Epoch 229/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0093 - r_square: 0.9969 - val_loss: 0.0446 - val_r_square: 0.9869\n",
            "Epoch 230/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0092 - r_square: 0.9969 - val_loss: 0.0446 - val_r_square: 0.9869\n",
            "Epoch 231/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0092 - r_square: 0.9970 - val_loss: 0.0445 - val_r_square: 0.9869\n",
            "Epoch 232/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0091 - r_square: 0.9970 - val_loss: 0.0445 - val_r_square: 0.9869\n",
            "Epoch 233/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0091 - r_square: 0.9970 - val_loss: 0.0443 - val_r_square: 0.9870\n",
            "Epoch 234/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0091 - r_square: 0.9970 - val_loss: 0.0442 - val_r_square: 0.9870\n",
            "Epoch 235/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0090 - r_square: 0.9970 - val_loss: 0.0440 - val_r_square: 0.9871\n",
            "Epoch 236/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0090 - r_square: 0.9970 - val_loss: 0.0438 - val_r_square: 0.9871\n",
            "Epoch 237/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0089 - r_square: 0.9971 - val_loss: 0.0436 - val_r_square: 0.9872\n",
            "Epoch 238/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0089 - r_square: 0.9971 - val_loss: 0.0434 - val_r_square: 0.9872\n",
            "Epoch 239/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0088 - r_square: 0.9971 - val_loss: 0.0432 - val_r_square: 0.9873\n",
            "Epoch 240/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0088 - r_square: 0.9971 - val_loss: 0.0431 - val_r_square: 0.9873\n",
            "Epoch 241/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0088 - r_square: 0.9971 - val_loss: 0.0430 - val_r_square: 0.9874\n",
            "Epoch 242/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0087 - r_square: 0.9971 - val_loss: 0.0429 - val_r_square: 0.9874\n",
            "Epoch 243/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0087 - r_square: 0.9971 - val_loss: 0.0428 - val_r_square: 0.9874\n",
            "Epoch 244/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0087 - r_square: 0.9971 - val_loss: 0.0427 - val_r_square: 0.9874\n",
            "Epoch 245/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0086 - r_square: 0.9972 - val_loss: 0.0426 - val_r_square: 0.9874\n",
            "Epoch 246/20000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - r_square: 0.9972 - val_loss: 0.0426 - val_r_square: 0.9875\n",
            "Epoch 247/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0085 - r_square: 0.9972 - val_loss: 0.0424 - val_r_square: 0.9875\n",
            "Epoch 248/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0085 - r_square: 0.9972 - val_loss: 0.0423 - val_r_square: 0.9875\n",
            "Epoch 249/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0085 - r_square: 0.9972 - val_loss: 0.0422 - val_r_square: 0.9876\n",
            "Epoch 250/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0084 - r_square: 0.9972 - val_loss: 0.0420 - val_r_square: 0.9876\n",
            "Epoch 251/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0084 - r_square: 0.9972 - val_loss: 0.0419 - val_r_square: 0.9877\n",
            "Epoch 252/20000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0084 - r_square: 0.9972 - val_loss: 0.0417 - val_r_square: 0.9877\n",
            "Epoch 253/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0083 - r_square: 0.9972 - val_loss: 0.0416 - val_r_square: 0.9878\n",
            "Epoch 254/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0083 - r_square: 0.9973 - val_loss: 0.0415 - val_r_square: 0.9878\n",
            "Epoch 255/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0083 - r_square: 0.9973 - val_loss: 0.0414 - val_r_square: 0.9878\n",
            "Epoch 256/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0082 - r_square: 0.9973 - val_loss: 0.0413 - val_r_square: 0.9879\n",
            "Epoch 257/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0082 - r_square: 0.9973 - val_loss: 0.0412 - val_r_square: 0.9879\n",
            "Epoch 258/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0082 - r_square: 0.9973 - val_loss: 0.0411 - val_r_square: 0.9879\n",
            "Epoch 259/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0081 - r_square: 0.9973 - val_loss: 0.0410 - val_r_square: 0.9879\n",
            "Epoch 260/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0081 - r_square: 0.9973 - val_loss: 0.0409 - val_r_square: 0.9880\n",
            "Epoch 261/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0081 - r_square: 0.9973 - val_loss: 0.0408 - val_r_square: 0.9880\n",
            "Epoch 262/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0081 - r_square: 0.9973 - val_loss: 0.0407 - val_r_square: 0.9880\n",
            "Epoch 263/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0080 - r_square: 0.9973 - val_loss: 0.0406 - val_r_square: 0.9881\n",
            "Epoch 264/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0080 - r_square: 0.9974 - val_loss: 0.0405 - val_r_square: 0.9881\n",
            "Epoch 265/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0080 - r_square: 0.9974 - val_loss: 0.0404 - val_r_square: 0.9881\n",
            "Epoch 266/20000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0079 - r_square: 0.9974 - val_loss: 0.0403 - val_r_square: 0.9882\n",
            "Epoch 267/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0079 - r_square: 0.9974 - val_loss: 0.0401 - val_r_square: 0.9882\n",
            "Epoch 268/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0079 - r_square: 0.9974 - val_loss: 0.0400 - val_r_square: 0.9882\n",
            "Epoch 269/20000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0079 - r_square: 0.9974 - val_loss: 0.0399 - val_r_square: 0.9882\n",
            "Epoch 270/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0078 - r_square: 0.9974 - val_loss: 0.0399 - val_r_square: 0.9883\n",
            "Epoch 271/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0078 - r_square: 0.9974 - val_loss: 0.0398 - val_r_square: 0.9883\n",
            "Epoch 272/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0078 - r_square: 0.9974 - val_loss: 0.0397 - val_r_square: 0.9883\n",
            "Epoch 273/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0078 - r_square: 0.9974 - val_loss: 0.0396 - val_r_square: 0.9883\n",
            "Epoch 274/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0077 - r_square: 0.9974 - val_loss: 0.0395 - val_r_square: 0.9884\n",
            "Epoch 275/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0077 - r_square: 0.9975 - val_loss: 0.0394 - val_r_square: 0.9884\n",
            "Epoch 276/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0077 - r_square: 0.9975 - val_loss: 0.0393 - val_r_square: 0.9884\n",
            "Epoch 277/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0077 - r_square: 0.9975 - val_loss: 0.0392 - val_r_square: 0.9885\n",
            "Epoch 278/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0077 - r_square: 0.9975 - val_loss: 0.0391 - val_r_square: 0.9885\n",
            "Epoch 279/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0076 - r_square: 0.9975 - val_loss: 0.0391 - val_r_square: 0.9885\n",
            "Epoch 280/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0076 - r_square: 0.9975 - val_loss: 0.0390 - val_r_square: 0.9885\n",
            "Epoch 281/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0076 - r_square: 0.9975 - val_loss: 0.0389 - val_r_square: 0.9886\n",
            "Epoch 282/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0076 - r_square: 0.9975 - val_loss: 0.0388 - val_r_square: 0.9886\n",
            "Epoch 283/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0075 - r_square: 0.9975 - val_loss: 0.0387 - val_r_square: 0.9886\n",
            "Epoch 284/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0075 - r_square: 0.9975 - val_loss: 0.0386 - val_r_square: 0.9886\n",
            "Epoch 285/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0075 - r_square: 0.9975 - val_loss: 0.0386 - val_r_square: 0.9887\n",
            "Epoch 286/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0075 - r_square: 0.9975 - val_loss: 0.0385 - val_r_square: 0.9887\n",
            "Epoch 287/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0075 - r_square: 0.9975 - val_loss: 0.0384 - val_r_square: 0.9887\n",
            "Epoch 288/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - r_square: 0.9975 - val_loss: 0.0383 - val_r_square: 0.9887\n",
            "Epoch 289/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0074 - r_square: 0.9976 - val_loss: 0.0382 - val_r_square: 0.9887\n",
            "Epoch 290/20000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0074 - r_square: 0.9976 - val_loss: 0.0382 - val_r_square: 0.9888\n",
            "Epoch 291/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - r_square: 0.9976 - val_loss: 0.0381 - val_r_square: 0.9888\n",
            "Epoch 292/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - r_square: 0.9976 - val_loss: 0.0380 - val_r_square: 0.9888\n",
            "Epoch 293/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0073 - r_square: 0.9976 - val_loss: 0.0379 - val_r_square: 0.9888\n",
            "Epoch 294/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0073 - r_square: 0.9976 - val_loss: 0.0379 - val_r_square: 0.9889\n",
            "Epoch 295/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0073 - r_square: 0.9976 - val_loss: 0.0378 - val_r_square: 0.9889\n",
            "Epoch 296/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0073 - r_square: 0.9976 - val_loss: 0.0377 - val_r_square: 0.9889\n",
            "Epoch 297/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0073 - r_square: 0.9976 - val_loss: 0.0376 - val_r_square: 0.9889\n",
            "Epoch 298/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0073 - r_square: 0.9976 - val_loss: 0.0376 - val_r_square: 0.9889\n",
            "Epoch 299/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0072 - r_square: 0.9976 - val_loss: 0.0375 - val_r_square: 0.9890\n",
            "Epoch 300/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0072 - r_square: 0.9976 - val_loss: 0.0374 - val_r_square: 0.9890\n",
            "Epoch 301/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0072 - r_square: 0.9976 - val_loss: 0.0374 - val_r_square: 0.9890\n",
            "Epoch 302/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0072 - r_square: 0.9976 - val_loss: 0.0373 - val_r_square: 0.9890\n",
            "Epoch 303/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0072 - r_square: 0.9976 - val_loss: 0.0373 - val_r_square: 0.9890\n",
            "Epoch 304/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0072 - r_square: 0.9976 - val_loss: 0.0372 - val_r_square: 0.9891\n",
            "Epoch 305/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0071 - r_square: 0.9976 - val_loss: 0.0371 - val_r_square: 0.9891\n",
            "Epoch 306/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0071 - r_square: 0.9976 - val_loss: 0.0371 - val_r_square: 0.9891\n",
            "Epoch 307/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0071 - r_square: 0.9977 - val_loss: 0.0370 - val_r_square: 0.9891\n",
            "Epoch 308/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0071 - r_square: 0.9977 - val_loss: 0.0369 - val_r_square: 0.9891\n",
            "Epoch 309/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0071 - r_square: 0.9977 - val_loss: 0.0369 - val_r_square: 0.9891\n",
            "Epoch 310/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0071 - r_square: 0.9977 - val_loss: 0.0368 - val_r_square: 0.9892\n",
            "Epoch 311/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0071 - r_square: 0.9977 - val_loss: 0.0368 - val_r_square: 0.9892\n",
            "Epoch 312/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0367 - val_r_square: 0.9892\n",
            "Epoch 313/20000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0367 - val_r_square: 0.9892\n",
            "Epoch 314/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0366 - val_r_square: 0.9892\n",
            "Epoch 315/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0365 - val_r_square: 0.9892\n",
            "Epoch 316/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0365 - val_r_square: 0.9893\n",
            "Epoch 317/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0364 - val_r_square: 0.9893\n",
            "Epoch 318/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0364 - val_r_square: 0.9893\n",
            "Epoch 319/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0070 - r_square: 0.9977 - val_loss: 0.0363 - val_r_square: 0.9893\n",
            "Epoch 320/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0362 - val_r_square: 0.9893\n",
            "Epoch 321/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0361 - val_r_square: 0.9894\n",
            "Epoch 322/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0360 - val_r_square: 0.9894\n",
            "Epoch 323/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0359 - val_r_square: 0.9894\n",
            "Epoch 324/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0359 - val_r_square: 0.9894\n",
            "Epoch 325/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0359 - val_r_square: 0.9894\n",
            "Epoch 326/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0360 - val_r_square: 0.9894\n",
            "Epoch 327/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0360 - val_r_square: 0.9894\n",
            "Epoch 328/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0360 - val_r_square: 0.9894\n",
            "Epoch 329/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0360 - val_r_square: 0.9894\n",
            "Epoch 330/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0360 - val_r_square: 0.9894\n",
            "Epoch 331/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0069 - r_square: 0.9977 - val_loss: 0.0359 - val_r_square: 0.9894\n",
            "Epoch 332/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9977 - val_loss: 0.0358 - val_r_square: 0.9895\n",
            "Epoch 333/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9977 - val_loss: 0.0357 - val_r_square: 0.9895\n",
            "Epoch 334/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9977 - val_loss: 0.0357 - val_r_square: 0.9895\n",
            "Epoch 335/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9977 - val_loss: 0.0356 - val_r_square: 0.9895\n",
            "Epoch 336/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0068 - r_square: 0.9977 - val_loss: 0.0355 - val_r_square: 0.9895\n",
            "Epoch 337/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9977 - val_loss: 0.0355 - val_r_square: 0.9896\n",
            "Epoch 338/20000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0355 - val_r_square: 0.9896\n",
            "Epoch 339/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0355 - val_r_square: 0.9896\n",
            "Epoch 340/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0355 - val_r_square: 0.9896\n",
            "Epoch 341/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0355 - val_r_square: 0.9896\n",
            "Epoch 342/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0355 - val_r_square: 0.9896\n",
            "Epoch 343/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0354 - val_r_square: 0.9896\n",
            "Epoch 344/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0354 - val_r_square: 0.9896\n",
            "Epoch 345/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0353 - val_r_square: 0.9896\n",
            "Epoch 346/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0353 - val_r_square: 0.9896\n",
            "Epoch 347/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0068 - r_square: 0.9978 - val_loss: 0.0352 - val_r_square: 0.9896\n",
            "Epoch 348/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0352 - val_r_square: 0.9896\n",
            "Epoch 349/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0351 - val_r_square: 0.9897\n",
            "Epoch 350/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0351 - val_r_square: 0.9897\n",
            "Epoch 351/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0351 - val_r_square: 0.9897\n",
            "Epoch 352/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0350 - val_r_square: 0.9897\n",
            "Epoch 353/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0350 - val_r_square: 0.9897\n",
            "Epoch 354/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0350 - val_r_square: 0.9897\n",
            "Epoch 355/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0350 - val_r_square: 0.9897\n",
            "Epoch 356/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0350 - val_r_square: 0.9897\n",
            "Epoch 357/20000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0349 - val_r_square: 0.9897\n",
            "Epoch 358/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0349 - val_r_square: 0.9897\n",
            "Epoch 359/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0348 - val_r_square: 0.9897\n",
            "Epoch 360/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0348 - val_r_square: 0.9898\n",
            "Epoch 361/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0348 - val_r_square: 0.9898\n",
            "Epoch 362/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0347 - val_r_square: 0.9898\n",
            "Epoch 363/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0347 - val_r_square: 0.9898\n",
            "Epoch 364/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0347 - val_r_square: 0.9898\n",
            "Epoch 365/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0346 - val_r_square: 0.9898\n",
            "Epoch 366/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0067 - r_square: 0.9978 - val_loss: 0.0346 - val_r_square: 0.9898\n",
            "Epoch 367/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0346 - val_r_square: 0.9898\n",
            "Epoch 368/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0346 - val_r_square: 0.9898\n",
            "Epoch 369/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0345 - val_r_square: 0.9898\n",
            "Epoch 370/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0345 - val_r_square: 0.9898\n",
            "Epoch 371/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0345 - val_r_square: 0.9899\n",
            "Epoch 372/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0344 - val_r_square: 0.9899\n",
            "Epoch 373/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0344 - val_r_square: 0.9899\n",
            "Epoch 374/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0344 - val_r_square: 0.9899\n",
            "Epoch 375/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0343 - val_r_square: 0.9899\n",
            "Epoch 376/20000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0343 - val_r_square: 0.9899\n",
            "Epoch 377/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0343 - val_r_square: 0.9899\n",
            "Epoch 378/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0343 - val_r_square: 0.9899\n",
            "Epoch 379/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0342 - val_r_square: 0.9899\n",
            "Epoch 380/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0342 - val_r_square: 0.9899\n",
            "Epoch 381/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0342 - val_r_square: 0.9899\n",
            "Epoch 382/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0342 - val_r_square: 0.9899\n",
            "Epoch 383/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0341 - val_r_square: 0.9900\n",
            "Epoch 384/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0341 - val_r_square: 0.9900\n",
            "Epoch 385/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0341 - val_r_square: 0.9900\n",
            "Epoch 386/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0341 - val_r_square: 0.9900\n",
            "Epoch 387/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0340 - val_r_square: 0.9900\n",
            "Epoch 388/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0340 - val_r_square: 0.9900\n",
            "Epoch 389/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0340 - val_r_square: 0.9900\n",
            "Epoch 390/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0066 - r_square: 0.9978 - val_loss: 0.0340 - val_r_square: 0.9900\n",
            "Epoch 391/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0339 - val_r_square: 0.9900\n",
            "Epoch 392/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0339 - val_r_square: 0.9900\n",
            "Epoch 393/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0339 - val_r_square: 0.9900\n",
            "Epoch 394/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0339 - val_r_square: 0.9900\n",
            "Epoch 395/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0338 - val_r_square: 0.9900\n",
            "Epoch 396/20000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0338 - val_r_square: 0.9900\n",
            "Epoch 397/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0338 - val_r_square: 0.9901\n",
            "Epoch 398/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0338 - val_r_square: 0.9901\n",
            "Epoch 399/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0337 - val_r_square: 0.9901\n",
            "Epoch 400/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9978 - val_loss: 0.0337 - val_r_square: 0.9901\n",
            "Epoch 401/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0337 - val_r_square: 0.9901\n",
            "Epoch 402/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0337 - val_r_square: 0.9901\n",
            "Epoch 403/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0337 - val_r_square: 0.9901\n",
            "Epoch 404/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0336 - val_r_square: 0.9901\n",
            "Epoch 405/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0336 - val_r_square: 0.9901\n",
            "Epoch 406/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0336 - val_r_square: 0.9901\n",
            "Epoch 407/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0336 - val_r_square: 0.9901\n",
            "Epoch 408/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0336 - val_r_square: 0.9901\n",
            "Epoch 409/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0335 - val_r_square: 0.9901\n",
            "Epoch 410/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0335 - val_r_square: 0.9901\n",
            "Epoch 411/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0335 - val_r_square: 0.9901\n",
            "Epoch 412/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0335 - val_r_square: 0.9901\n",
            "Epoch 413/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0335 - val_r_square: 0.9902\n",
            "Epoch 414/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0334 - val_r_square: 0.9902\n",
            "Epoch 415/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0334 - val_r_square: 0.9902\n",
            "Epoch 416/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0334 - val_r_square: 0.9902\n",
            "Epoch 417/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0334 - val_r_square: 0.9902\n",
            "Epoch 418/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0334 - val_r_square: 0.9902\n",
            "Epoch 419/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0333 - val_r_square: 0.9902\n",
            "Epoch 420/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0333 - val_r_square: 0.9902\n",
            "Epoch 421/20000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - r_square: 0.9979 - val_loss: 0.0333 - val_r_square: 0.9902\n",
            "Epoch 422/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0333 - val_r_square: 0.9902\n",
            "Epoch 423/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0333 - val_r_square: 0.9902\n",
            "Epoch 424/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0333 - val_r_square: 0.9902\n",
            "Epoch 425/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0332 - val_r_square: 0.9902\n",
            "Epoch 426/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0332 - val_r_square: 0.9902\n",
            "Epoch 427/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0332 - val_r_square: 0.9902\n",
            "Epoch 428/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0332 - val_r_square: 0.9902\n",
            "Epoch 429/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0332 - val_r_square: 0.9902\n",
            "Epoch 430/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0332 - val_r_square: 0.9902\n",
            "Epoch 431/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0331 - val_r_square: 0.9902\n",
            "Epoch 432/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0331 - val_r_square: 0.9903\n",
            "Epoch 433/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0331 - val_r_square: 0.9903\n",
            "Epoch 434/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0331 - val_r_square: 0.9903\n",
            "Epoch 435/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0331 - val_r_square: 0.9903\n",
            "Epoch 436/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0331 - val_r_square: 0.9903\n",
            "Epoch 437/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0330 - val_r_square: 0.9903\n",
            "Epoch 438/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0330 - val_r_square: 0.9903\n",
            "Epoch 439/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0330 - val_r_square: 0.9903\n",
            "Epoch 440/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0330 - val_r_square: 0.9903\n",
            "Epoch 441/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0330 - val_r_square: 0.9903\n",
            "Epoch 442/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0330 - val_r_square: 0.9903\n",
            "Epoch 443/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0330 - val_r_square: 0.9903\n",
            "Epoch 444/20000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 445/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 446/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 447/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 448/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 449/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 450/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 451/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0329 - val_r_square: 0.9903\n",
            "Epoch 452/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9903\n",
            "Epoch 453/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9903\n",
            "Epoch 454/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9903\n",
            "Epoch 455/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9903\n",
            "Epoch 456/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9904\n",
            "Epoch 457/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9904\n",
            "Epoch 458/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9904\n",
            "Epoch 459/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0328 - val_r_square: 0.9904\n",
            "Epoch 460/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 461/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 462/20000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 463/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 464/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 465/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 466/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 467/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 468/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 469/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0327 - val_r_square: 0.9904\n",
            "Epoch 470/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 471/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 472/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 473/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 474/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 475/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 476/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 477/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 478/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 479/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0326 - val_r_square: 0.9904\n",
            "Epoch 480/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 481/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 482/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 483/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 484/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 485/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 486/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 487/20000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 488/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 489/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 490/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 491/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 492/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0325 - val_r_square: 0.9904\n",
            "Epoch 493/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 494/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 495/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 496/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 497/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 498/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 499/20000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 500/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 501/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 502/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 503/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 504/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 505/20000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 506/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 507/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0324 - val_r_square: 0.9905\n",
            "Epoch 508/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 509/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 510/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 511/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 512/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 513/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 514/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 515/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 516/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 517/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 518/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 519/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 520/20000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 521/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 522/20000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 523/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 524/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 525/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 526/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 527/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 528/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 529/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 530/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 531/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 532/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 533/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 534/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 535/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 536/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 537/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 538/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 539/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 540/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 541/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 542/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 543/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 544/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 545/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 546/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 547/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 548/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 549/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 550/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 551/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 552/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 553/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 554/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 555/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 556/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 557/20000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 558/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 559/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 560/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 561/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 562/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 563/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 564/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 565/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 566/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 567/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 568/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 569/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 570/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 571/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 572/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 573/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 574/20000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 575/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 576/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 577/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 578/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 579/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 580/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 581/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 582/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 583/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 584/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 585/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 586/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 587/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 588/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 589/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 590/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 591/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 592/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 593/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 594/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 595/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 596/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 597/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 598/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 599/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 600/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 601/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 602/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 603/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 604/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 605/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 606/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 607/20000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 608/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 609/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 610/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 611/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 612/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 613/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 614/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 615/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 616/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 617/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 618/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 619/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 620/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 621/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 622/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 623/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 624/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 625/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 626/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 627/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 628/20000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 629/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 630/20000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 631/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 632/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 633/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 634/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 635/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 636/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 637/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 638/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 639/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 640/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 641/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 642/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 643/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 644/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 645/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 646/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 647/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 648/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 649/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 650/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 651/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 652/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 653/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 654/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 655/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 656/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 657/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 658/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 659/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 660/20000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 661/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 662/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 663/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 664/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 665/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 666/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 667/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0320 - val_r_square: 0.9906\n",
            "Epoch 668/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 669/20000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 670/20000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0062 - r_square: 0.9979 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 671/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 672/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 673/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 674/20000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 675/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 676/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 677/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 678/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 679/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 680/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 681/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 682/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 683/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 684/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 685/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 686/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 687/20000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 688/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 689/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 690/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 691/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 692/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 693/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 694/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 695/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 696/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 697/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 698/20000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 699/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 700/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 701/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 702/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 703/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 704/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 705/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 706/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 707/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 708/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 709/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 710/20000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 711/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 712/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 713/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 714/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 715/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 716/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 717/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 718/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 719/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 720/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 721/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 722/20000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 723/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 724/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 725/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 726/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 727/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 728/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 729/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 730/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 731/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 732/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 733/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 734/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 735/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 736/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9906\n",
            "Epoch 737/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 738/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 739/20000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 740/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 741/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 742/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 743/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 744/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 745/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 746/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 747/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 748/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 749/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 750/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 751/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 752/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 753/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 754/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 755/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 756/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 757/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 758/20000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 759/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 760/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 761/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 762/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 763/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 764/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0321 - val_r_square: 0.9905\n",
            "Epoch 765/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 766/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 767/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 768/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 769/20000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 770/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 771/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 772/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 773/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 774/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 775/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 776/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 777/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 778/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 779/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 780/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 781/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 782/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 783/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 784/20000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 785/20000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 786/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 787/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 788/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 789/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 790/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 791/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 792/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 793/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 794/20000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 795/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 796/20000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 797/20000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 798/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 799/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 800/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 801/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 802/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 803/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 804/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 805/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 806/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 807/20000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 808/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 809/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 810/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 811/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 812/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 813/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 814/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 815/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 816/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 817/20000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 818/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 819/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 820/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 821/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 822/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 823/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 824/20000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 825/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 826/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 827/20000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 828/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 829/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 830/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 831/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 832/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 833/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 834/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 835/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0322 - val_r_square: 0.9905\n",
            "Epoch 836/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 837/20000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 838/20000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 839/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 840/20000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 841/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 842/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 843/20000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 844/20000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n",
            "Epoch 845/20000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - r_square: 0.9980 - val_loss: 0.0323 - val_r_square: 0.9905\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss = tf.keras.losses.mean_squared_error,\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics = [tfa.metrics.RSquare()])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)\n",
        "\n",
        "hist = model.fit(\n",
        "    x = X,\n",
        "    y = Y,\n",
        "    batch_size = 256,\n",
        "    epochs = 20000,\n",
        "    shuffle = False,\n",
        "    validation_data=(X_t, Y_t),\n",
        "    callbacks=[callback],\n",
        "    verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "644\n",
            "0.990570604801178\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "a = np.argmax(hist.history['val_r_square'])\n",
        "print(a)\n",
        "print(hist.history['val_r_square'][a])\n",
        "# plot metrics\n",
        "plt.plot(hist.history['val_r_square'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 560us/step - loss: 0.0323 - r_square: 0.9905\n",
            "R2 test data: 0.9905019998550415\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"R2 test data:\", model.evaluate(X_t, Y_t)[1])\n",
        "\n",
        "plt.figure(figsize=(10,2))\n",
        "plt.plot(model(X_t), label='predicted')\n",
        "plt.plot(Y_t, label='real')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "912d6611990680b3d240e982c9d50f3da4c776707cfd42695cf7d82c88d80956"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
