{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jzH_LbEIGLWu"
      },
      "outputs": [],
      "source": [
        "# library\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchmetrics import R2Score\n",
        "\n",
        "r2score = R2Score()\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y3eaKBL2GhJI"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "class MonotonicLinear(torch.nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.input_size  = input_size\n",
        "    self.output_size = output_size\n",
        "    self.weights = torch.nn.Parameter(torch.rand((output_size, input_size), dtype=torch.float32))\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = torch.mm(x, torch.exp(self.weights.t()))\n",
        "    return z\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.input11 = MonotonicLinear(1, 4)\n",
        "    self.input12 = torch.nn.Linear(2, 4)\n",
        "    self.max1    = torch.nn.MaxPool1d(4)\n",
        "\n",
        "    self.input21 = MonotonicLinear(1, 4)\n",
        "    self.input22 = torch.nn.Linear(2, 4)\n",
        "    self.max2    = torch.nn.MaxPool1d(4)\n",
        "\n",
        "    self.output = torch.nn.MaxPool1d(2)\n",
        "\n",
        "  def forward(self, x_m, x_u):\n",
        "    z1 = torch.add(self.input11(x_m), self.input12(x_u))\n",
        "    z1 = self.max1(z1)\n",
        "\n",
        "    z2 = torch.add(self.input21(x_m), self.input22(x_u))\n",
        "    z2 = self.max1(z2)\n",
        "\n",
        "    z = torch.concat((z1,z2), axis=1)\n",
        "    z = self.output(-z)\n",
        "\n",
        "    return -z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BtNtb3epPIzJ"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "def eval(model, testset):\n",
        "    with torch.no_grad():\n",
        "        pred_Y = model(testset.x_m_data, testset.x_u_data)\n",
        "    \n",
        "    r2 = r2score(pred_Y, testset.y_data)\n",
        "    return r2.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dTWtNEdVHCuw"
      },
      "outputs": [],
      "source": [
        "# Data class\n",
        "class Data(torch.utils.data.Dataset):\n",
        "  def __init__(self, src_file, start=None, end=None):\n",
        "    df = pd.read_csv(src_file)\n",
        "    Tsa_k1 = np.array(df['supply_discharge_temp']).reshape(-1,1)[start+1: end+1]\n",
        "    Tz_k   = np.array(df['room_temp']).reshape(-1,1)[start: end]\n",
        "    msa_k1 = np.array(df['airflow_current']).reshape(-1,1)[start+1: end+1]\n",
        "\n",
        "    tmp_x_u = np.concatenate((Tz_k, msa_k1), axis=1)\n",
        "    tmp_y   = np.array(df['room_temp']).reshape(-1,1)[start+1: end+1]\n",
        "\n",
        "    self.x_m_data = torch.tensor(Tsa_k1, dtype=torch.float32)\n",
        "    self.x_u_data = torch.tensor(tmp_x_u, dtype=torch.float32)\n",
        "    self.y_data   = torch.tensor(tmp_y, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    inp_m  = self.x_m_data[idx]\n",
        "    inp_u  = self.x_u_data[idx]\n",
        "    outp   = self.y_data[idx]\n",
        "    sample = {'inp_m':inp_m, 'inp_u':inp_u, 'outp':outp}\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Early stopping function\n",
        "def early_stop(list, min_epochs, patience):\n",
        "    if(len(list) > min_epochs):\n",
        "        if(np.max(list[-patience:]) < 1.00001*np.max(list[0: -patience])):\n",
        "            return 1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gebr4CnRLFBd",
        "outputId": "d74e7cd7-8dab-49a9-babc-e77577dd73b7"
      },
      "outputs": [],
      "source": [
        "# train function\n",
        "def train(net, train_ds, test_ds, lr=0.001, min_epochs=200, max_epochs=100000, patience=100, smooth=0):\n",
        "    loss_func  = torch.nn.MSELoss()\n",
        "    optimizer  = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    R2_test    = np.array([])\n",
        "    train_ldr = torch.utils.data.DataLoader(train_ds, batch_size=train_ds.y_data.shape[0], shuffle=True)\n",
        "    for _ in range(0, max_epochs+1):\n",
        "        net.train()\n",
        "        for (_, batch) in enumerate(train_ldr):\n",
        "            X_m = batch['inp_m']\n",
        "            X_u = batch['inp_u']\n",
        "            Y   = batch['outp']\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net(X_m, X_u)\n",
        "            loss_val = loss_func(output, Y) + smooth*loss_func(output, X_u[:,0].reshape(-1,1))\n",
        "            loss_val.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        net.eval()\n",
        "        R2_test = np.append(R2_test, eval(net, test_ds))\n",
        "        \n",
        "        if(early_stop(list = R2_test, min_epochs = min_epochs, patience = patience) == 1):\n",
        "            break\n",
        "    \n",
        "    return R2_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n train =  16 \t smooth = 0.0000 \t lr = 0.0001 \t best_epoch = 24697 \t best_R2 = -1162.77515\n",
            "n train =  16 \t smooth = 0.0000 \t lr = 0.0010 \t best_epoch = 49848 \t best_R2 = -707.26892\n",
            "n train =  16 \t smooth = 0.0000 \t lr = 0.0100 \t best_epoch =    38 \t best_R2 = -260.12985\n",
            "n train =  16 \t smooth = 0.0000 \t lr = 0.1000 \t best_epoch =    13 \t best_R2 = -70.25680\n",
            "n train =  16 \t smooth = 0.0000 \t lr = 0.2000 \t best_epoch =    25 \t best_R2 = -57.88739\n",
            "n train =  16 \t smooth = 0.0000 \t lr = 0.5000 \t best_epoch =    22 \t best_R2 = -69.02117\n",
            "n train =  16 \t smooth = 0.0010 \t lr = 0.0001 \t best_epoch = 18586 \t best_R2 = -1065.83582\n",
            "n train =  16 \t smooth = 0.0010 \t lr = 0.0010 \t best_epoch = 10197 \t best_R2 = -81.71529\n",
            "n train =  16 \t smooth = 0.0010 \t lr = 0.0100 \t best_epoch =   102 \t best_R2 = -110.39674\n",
            "n train =  16 \t smooth = 0.0010 \t lr = 0.1000 \t best_epoch =    13 \t best_R2 = -218.08696\n",
            "n train =  16 \t smooth = 0.0010 \t lr = 0.2000 \t best_epoch =    29 \t best_R2 = -57.81140\n",
            "n train =  16 \t smooth = 0.0010 \t lr = 0.5000 \t best_epoch =    11 \t best_R2 = -33.55088\n",
            "n train =  16 \t smooth = 0.0100 \t lr = 0.0001 \t best_epoch = 49962 \t best_R2 = -743.52960\n",
            "n train =  16 \t smooth = 0.0100 \t lr = 0.0010 \t best_epoch =  1409 \t best_R2 = -833.59039\n",
            "n train =  16 \t smooth = 0.0100 \t lr = 0.0100 \t best_epoch =    21 \t best_R2 = -487.15540\n",
            "n train =  16 \t smooth = 0.0100 \t lr = 0.1000 \t best_epoch =    15 \t best_R2 = -49.95807\n",
            "n train =  16 \t smooth = 0.0100 \t lr = 0.2000 \t best_epoch =    56 \t best_R2 = -17.83583\n",
            "n train =  16 \t smooth = 0.0100 \t lr = 0.5000 \t best_epoch =    32 \t best_R2 = -23.34010\n",
            "n train =  32 \t smooth = 0.0000 \t lr = 0.0001 \t best_epoch =  7012 \t best_R2 = -39.01590\n",
            "n train =  32 \t smooth = 0.0000 \t lr = 0.0010 \t best_epoch =   275 \t best_R2 = -22.98758\n",
            "n train =  32 \t smooth = 0.0000 \t lr = 0.0100 \t best_epoch =    42 \t best_R2 = -24.81115\n",
            "n train =  32 \t smooth = 0.0000 \t lr = 0.1000 \t best_epoch =   151 \t best_R2 = -33.15823\n",
            "n train =  32 \t smooth = 0.0000 \t lr = 0.2000 \t best_epoch =    17 \t best_R2 = -171.28458\n",
            "n train =  32 \t smooth = 0.0000 \t lr = 0.5000 \t best_epoch =    45 \t best_R2 = -43.41593\n",
            "n train =  32 \t smooth = 0.0010 \t lr = 0.0001 \t best_epoch =  2270 \t best_R2 = -39.41186\n",
            "n train =  32 \t smooth = 0.0010 \t lr = 0.0010 \t best_epoch =  5836 \t best_R2 = -31.09932\n",
            "n train =  32 \t smooth = 0.0010 \t lr = 0.0100 \t best_epoch =    33 \t best_R2 = -31.97136\n",
            "n train =  32 \t smooth = 0.0010 \t lr = 0.1000 \t best_epoch =    14 \t best_R2 = -26.23096\n",
            "n train =  32 \t smooth = 0.0010 \t lr = 0.2000 \t best_epoch =    31 \t best_R2 = -20.11066\n",
            "n train =  32 \t smooth = 0.0010 \t lr = 0.5000 \t best_epoch =    56 \t best_R2 = -37.36298\n",
            "n train =  32 \t smooth = 0.0100 \t lr = 0.0001 \t best_epoch =  6681 \t best_R2 = -16.48179\n",
            "n train =  32 \t smooth = 0.0100 \t lr = 0.0010 \t best_epoch =  1633 \t best_R2 = -43.57976\n",
            "n train =  32 \t smooth = 0.0100 \t lr = 0.0100 \t best_epoch =   361 \t best_R2 = -6.39381\n",
            "n train =  32 \t smooth = 0.0100 \t lr = 0.1000 \t best_epoch =    32 \t best_R2 = -35.52970\n",
            "n train =  32 \t smooth = 0.0100 \t lr = 0.2000 \t best_epoch =    48 \t best_R2 = -6.51141\n",
            "n train =  32 \t smooth = 0.0100 \t lr = 0.5000 \t best_epoch =    47 \t best_R2 = -12.28315\n",
            "n train =  64 \t smooth = 0.0000 \t lr = 0.0001 \t best_epoch =  4278 \t best_R2 = -61.91193\n",
            "n train =  64 \t smooth = 0.0000 \t lr = 0.0010 \t best_epoch = 22553 \t best_R2 = 0.99811\n",
            "n train =  64 \t smooth = 0.0000 \t lr = 0.0100 \t best_epoch = 17621 \t best_R2 = 0.99791\n",
            "n train =  64 \t smooth = 0.0000 \t lr = 0.1000 \t best_epoch = 12605 \t best_R2 = 0.99813\n",
            "n train =  64 \t smooth = 0.0000 \t lr = 0.2000 \t best_epoch = 11931 \t best_R2 = 0.99802\n",
            "n train =  64 \t smooth = 0.0000 \t lr = 0.5000 \t best_epoch =  5306 \t best_R2 = 0.99780\n",
            "n train =  64 \t smooth = 0.0010 \t lr = 0.0001 \t best_epoch = 50000 \t best_R2 = 0.96201\n",
            "n train =  64 \t smooth = 0.0010 \t lr = 0.0010 \t best_epoch =  2510 \t best_R2 = -3.64075\n",
            "n train =  64 \t smooth = 0.0010 \t lr = 0.0100 \t best_epoch = 16579 \t best_R2 = 0.99823\n",
            "n train =  64 \t smooth = 0.0010 \t lr = 0.1000 \t best_epoch = 13046 \t best_R2 = 0.99778\n",
            "n train =  64 \t smooth = 0.0010 \t lr = 0.2000 \t best_epoch = 11609 \t best_R2 = 0.99805\n",
            "n train =  64 \t smooth = 0.0010 \t lr = 0.5000 \t best_epoch =  8927 \t best_R2 = 0.99797\n",
            "n train =  64 \t smooth = 0.0100 \t lr = 0.0001 \t best_epoch =  6295 \t best_R2 = -64.37362\n",
            "n train =  64 \t smooth = 0.0100 \t lr = 0.0010 \t best_epoch =  4130 \t best_R2 = -12.31757\n",
            "n train =  64 \t smooth = 0.0100 \t lr = 0.0100 \t best_epoch = 23823 \t best_R2 = 0.99823\n",
            "n train =  64 \t smooth = 0.0100 \t lr = 0.1000 \t best_epoch = 14378 \t best_R2 = 0.99816\n",
            "n train =  64 \t smooth = 0.0100 \t lr = 0.2000 \t best_epoch =  9899 \t best_R2 = 0.99790\n",
            "n train =  64 \t smooth = 0.0100 \t lr = 0.5000 \t best_epoch =  9017 \t best_R2 = 0.99792\n",
            "n train = 128 \t smooth = 0.0000 \t lr = 0.0001 \t best_epoch =   116 \t best_R2 = -31.46632\n",
            "n train = 128 \t smooth = 0.0000 \t lr = 0.0010 \t best_epoch = 25780 \t best_R2 = 0.99823\n",
            "n train = 128 \t smooth = 0.0000 \t lr = 0.0100 \t best_epoch = 13873 \t best_R2 = -0.10566\n",
            "n train = 128 \t smooth = 0.0000 \t lr = 0.1000 \t best_epoch = 13314 \t best_R2 = 0.99754\n",
            "n train = 128 \t smooth = 0.0000 \t lr = 0.2000 \t best_epoch = 11136 \t best_R2 = 0.99792\n",
            "n train = 128 \t smooth = 0.0000 \t lr = 0.5000 \t best_epoch =  8551 \t best_R2 = 0.99803\n",
            "n train = 128 \t smooth = 0.0010 \t lr = 0.0001 \t best_epoch = 10498 \t best_R2 = -23.24826\n",
            "n train = 128 \t smooth = 0.0010 \t lr = 0.0010 \t best_epoch =   420 \t best_R2 = -100.83144\n",
            "n train = 128 \t smooth = 0.0010 \t lr = 0.0100 \t best_epoch = 12412 \t best_R2 = -2.36646\n",
            "n train = 128 \t smooth = 0.0010 \t lr = 0.1000 \t best_epoch = 15856 \t best_R2 = 0.99813\n",
            "n train = 128 \t smooth = 0.0010 \t lr = 0.2000 \t best_epoch = 11475 \t best_R2 = 0.99803\n",
            "n train = 128 \t smooth = 0.0010 \t lr = 0.5000 \t best_epoch =  7606 \t best_R2 = 0.99768\n",
            "n train = 128 \t smooth = 0.0100 \t lr = 0.0001 \t best_epoch =  9079 \t best_R2 = -29.53861\n",
            "n train = 128 \t smooth = 0.0100 \t lr = 0.0010 \t best_epoch = 12250 \t best_R2 = 0.63900\n",
            "n train = 128 \t smooth = 0.0100 \t lr = 0.0100 \t best_epoch =  1187 \t best_R2 = -6.29787\n",
            "n train = 128 \t smooth = 0.0100 \t lr = 0.1000 \t best_epoch = 15946 \t best_R2 = 0.99790\n",
            "n train = 128 \t smooth = 0.0100 \t lr = 0.2000 \t best_epoch = 11823 \t best_R2 = 0.99796\n",
            "n train = 128 \t smooth = 0.0100 \t lr = 0.5000 \t best_epoch =  7343 \t best_R2 = 0.99804\n"
          ]
        }
      ],
      "source": [
        "# main\n",
        "for _n_train in [16, 32, 64, 128]:\n",
        "    for _smooth in [0, 0.001, 0.01]:\n",
        "        for _lr in [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5]:\n",
        "\n",
        "            # Create network\n",
        "            device = torch.device(\"cpu\")\n",
        "            net = Net().to(device)\n",
        "\n",
        "            # Create Dataset and DataLoader objects\n",
        "            src_file = 'C:/Users/tln229/Downloads/Python/1. Building/data/HVAC_B90_102_exp_10m_20210424.csv'\n",
        "            n_train  = _n_train\n",
        "            train_ds = Data(src_file, start=0,       end=n_train)\n",
        "            test_ds  = Data(src_file, start=n_train, end=1600)\n",
        "\n",
        "            # train\n",
        "            R2_test = train(net, train_ds, test_ds, lr=_lr, min_epochs=500, max_epochs=50000, patience=300, smooth=_smooth)\n",
        "\n",
        "            # results\n",
        "            print('n train = %3d \\t smooth = %6.4f \\t lr = %6.4f \\t best_epoch = %5d \\t best_R2 = %7.5f'\n",
        "                % (_n_train, _smooth, _lr, np.argmax(R2_test), np.max(R2_test)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3. T_z .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "912d6611990680b3d240e982c9d50f3da4c776707cfd42695cf7d82c88d80956"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
