{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/tln229/Downloads/Python/1. Building/data/HVAC_B90_102_exp_10m_20210424.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGPModel(gp.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MyGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module  = gp.means.ZeroMean()\n",
    "        self.covar_module = gp.kernels.ScaleKernel(gp.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x  = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gp.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tln229\\Downloads\\Python\\1. Building\\Finals\\2. Supply Air model\\GP.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tln229/Downloads/Python/1.%20Building/Finals/2.%20Supply%20Air%20model/GP.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m output \u001b[39m=\u001b[39m model(train_x)         \u001b[39m# Output from model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tln229/Downloads/Python/1.%20Building/Finals/2.%20Supply%20Air%20model/GP.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m loss   \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmll(output, train_y)  \u001b[39m# Calc loss and backprop gradients\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tln229/Downloads/Python/1.%20Building/Finals/2.%20Supply%20Air%20model/GP.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tln229/Downloads/Python/1.%20Building/Finals/2.%20Supply%20Air%20model/GP.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tln229/Downloads/Python/1.%20Building/Finals/2.%20Supply%20Air%20model/GP.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# EVAL\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tln229\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\tln229\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:166\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    162\u001b[0m inputs \u001b[39m=\u001b[39m (inputs,) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m \\\n\u001b[0;32m    163\u001b[0m     \u001b[39mtuple\u001b[39m(inputs) \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[0;32m    165\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[1;32m--> 166\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[1;32mc:\\Users\\tln229\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:67\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mrequires_grad:\n\u001b[0;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mnumel() \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mones_like(out, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format))\n\u001b[0;32m     69\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "for n_train in ([32, 64, 128]):\n",
    "    for lr in ([0.001, 0.01, 0.02, 0.05]):\n",
    "\n",
    "        # TRAIN SET\n",
    "        Tca_k1   = np.array(df['ahu_supply_temp']).reshape(-1,1)[1: n_train+1]\n",
    "        Tsa_k    = np.array(df['supply_discharge_temp']).reshape(-1,1)[0: n_train]\n",
    "        Tsa_k1   = np.array(df['supply_discharge_temp']).reshape(-1,1)[1: n_train+1]\n",
    "        Tsa_k2   = np.array(df['supply_discharge_temp'])[2: n_train+2]\n",
    "        valve_k2 = np.array(df['htg_valve_position']).reshape(-1,1)[2: n_train+2]\n",
    "\n",
    "        train_x = np.concatenate((Tca_k1, Tsa_k, Tsa_k1, valve_k2), axis=1)\n",
    "        train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "        train_y = torch.tensor(Tsa_k2, dtype=torch.float32)\n",
    "\n",
    "        # TEST SET\n",
    "        Tca_k1   = np.array(df['ahu_supply_temp']).reshape(-1,1)[n_train+1: 1600+1]\n",
    "        Tsa_k    = np.array(df['supply_discharge_temp']).reshape(-1,1)[n_train: 1600]\n",
    "        Tsa_k1   = np.array(df['supply_discharge_temp']).reshape(-1,1)[n_train+1: 1600+1]\n",
    "        Tsa_k2   = np.array(df['supply_discharge_temp'])[n_train+2: 1600+2]\n",
    "        valve_k2 = np.array(df['htg_valve_position']).reshape(-1,1)[n_train+2: 1600+2]\n",
    "\n",
    "        test_x = np.concatenate((Tca_k1, Tsa_k, Tsa_k1, valve_k2), axis=1)\n",
    "        test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "        test_y = torch.tensor(Tsa_k2, dtype=torch.float32)\n",
    "\n",
    "        # initialize likelihood and model\n",
    "        likelihood = gp.likelihoods.GaussianLikelihood()\n",
    "        model      = MyGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "        # Training\n",
    "        training_iter = 200000    # number of training iteration\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)       # optimizer\n",
    "        mll = gp.mlls.ExactMarginalLogLikelihood(likelihood, model)   # marginal likelihood\n",
    "\n",
    "        R2_test = np.array([], dtype=np.float32)\n",
    "        for i in range(training_iter+1):\n",
    "            # TRAIN\n",
    "            model.train()                   # find the hyperparameters\n",
    "            likelihood.train()\n",
    "\n",
    "            optimizer.zero_grad()           # Zero gradients from previous iteration\n",
    "            output = model(train_x)         # Output from model\n",
    "            loss   = -mll(output, train_y)  # Calc loss and backprop gradients\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # EVAL\n",
    "            model.eval()\n",
    "            likelihood.eval()\n",
    "\n",
    "            with torch.no_grad(), gp.settings.fast_pred_var():\n",
    "                pred_y = likelihood(model(test_x))\n",
    "\n",
    "            r2 = r2_score(test_y.numpy(), pred_y.mean.numpy())\n",
    "            R2_test = np.append(R2_test, r2)\n",
    "        \n",
    "        # print(np.argmax(R2_test))\n",
    "        print('n:%4d \\t lr:%5.3f \\t r2:%8.4f' % (n_train, lr, np.max(R2_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "912d6611990680b3d240e982c9d50f3da4c776707cfd42695cf7d82c88d80956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
