{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4jzKgPZ5D81V"
      },
      "outputs": [],
      "source": [
        "# library\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "torch.set_printoptions(precision=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HAEV0sGeEEAE"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, s):\n",
        "        super(Net, self).__init__()\n",
        "        self.input   = torch.nn.Linear(3, s)\n",
        "        self.output  = torch.nn.Linear(s, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = torch.tanh(self.input(x))\n",
        "        z = self.output(z)\n",
        "        z = torch.relu(100 - torch.relu(z))\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8x017P0OEFVH"
      },
      "outputs": [],
      "source": [
        "# Model error\n",
        "def eval(model, testset, p):\n",
        "    with torch.no_grad():\n",
        "        pred_Y = model(testset.x_data)\n",
        "    \n",
        "    # R^2 qrh\n",
        "    r2_qrh = r2_score(testset.y_data, pred_Y)\n",
        "\n",
        "    # R^2 msa\n",
        "    pred_msa = pred_Y*p[0] + p[1]\n",
        "    r2_msa = r2_score(testset.msa_data, pred_msa)\n",
        "    \n",
        "    return r2_qrh, r2_msa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GjhVDtdREKfV"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "class Data(torch.utils.data.Dataset):\n",
        "  def __init__(self, src_file, start=None, end=None):\n",
        "    df = pd.read_csv(src_file)\n",
        "    clg_sp       = np.array(df['clg_sp_current']).reshape(-1,1)[start: end]\n",
        "    htg_sp       = np.array(df['htg_sp_current']).reshape(-1,1)[start: end]\n",
        "    htg_clg_mode = 1*np.array(df['htg_clg_mode']).reshape(-1,1)[start: end]\n",
        "\n",
        "    sp_k   = htg_sp*htg_clg_mode + clg_sp*(1-htg_clg_mode)\n",
        "    Tz_k   = np.array(df['thermostat_room_temp']).reshape(-1,1)[start: end]\n",
        "    qrh_k  = np.array(df['htg_valve_position']).reshape(-1,1)[start: end]\n",
        "    qrh_k1 = np.array(df['htg_valve_position']).reshape(-1,1)[start+1: end+1]\n",
        "    msa_k1 = np.array(df['airflow_current']).reshape(-1,1)[start+1: end+1]\n",
        "    tmp_x  = np.concatenate((sp_k, Tz_k, qrh_k), axis=1)\n",
        "    \n",
        "    self.x_data   = torch.tensor(tmp_x,  dtype=torch.float32)\n",
        "    self.y_data   = torch.tensor(qrh_k1, dtype=torch.float32)\n",
        "    self.msa_data = torch.tensor(msa_k1, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    inp  = self.x_data[idx]\n",
        "    outp = self.y_data[idx]\n",
        "    msa  = self.msa_data[idx]\n",
        "    sample = {'inp':inp, 'outp':outp, 'msa':msa}\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Early stopping\n",
        "def early_stop(list, min_epochs, patience):\n",
        "    if(len(list) > min_epochs):\n",
        "        if(np.max(list[-patience:]) < 1.0001*np.max(list[0: -patience])):\n",
        "            return 1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNRSA74gELy0",
        "outputId": "81e6dec5-e0ee-448f-c67b-22411ed38c4e"
      },
      "outputs": [],
      "source": [
        "# train function\n",
        "def train(net, p, train_ds, test_ds, lr=0.001, min_epochs=200, max_epochs=100000, patience=100, smooth=0):\n",
        "    \n",
        "    loss_func  = torch.nn.MSELoss()\n",
        "    optimizer  = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    train_ldr = torch.utils.data.DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "    R2_qrh = np.array([])\n",
        "    R2_msa = np.array([])\n",
        "    for _ in range(0, max_epochs+1):\n",
        "        net.train()\n",
        "        loss  = 0\n",
        "        count = 0\n",
        "        for (_, batch) in enumerate(train_ldr):\n",
        "            X    = batch['inp']\n",
        "            Y    = batch['outp']\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net(X)                    # compute the output of the Network\n",
        "            loss_val = loss_func(output, Y) + smooth*loss_func(output, X[:,2].reshape(-1,1))\n",
        "            loss += loss_val.item()            # accumulate\n",
        "            loss_val.backward()                # gradients\n",
        "            optimizer.step()                   # update paramters\n",
        "            count += 1\n",
        "\n",
        "        net.eval()\n",
        "        R2_qrh = np.append(R2_qrh, eval(net, test_ds, p)[0].item())\n",
        "        R2_msa = np.append(R2_msa, eval(net, test_ds, p)[1].item())\n",
        "        \n",
        "        if(early_stop(list = R2_qrh, min_epochs = min_epochs, patience = patience) == 1):\n",
        "            break\n",
        "    \n",
        "    return R2_qrh, R2_msa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     n_train  smooth  size      lr  best_epoch  R2_qrh  R2_msa\n",
            "0       32.0   0.000  16.0  0.0001         2.0 -2.1852 -2.1201\n",
            "1       32.0   0.000  16.0  0.0010         2.0 -2.1600 -2.0953\n",
            "2       32.0   0.000  16.0  0.0100         2.0 -2.1270 -2.0632\n",
            "3       32.0   0.000  16.0  0.1000         0.0 -2.1956 -2.1300\n",
            "4       32.0   0.000  32.0  0.0001         2.0 -2.1932 -2.1277\n",
            "5       32.0   0.000  32.0  0.0010         0.0 -2.1956 -2.1300\n",
            "6       32.0   0.000  32.0  0.0100         0.0 -2.1956 -2.1300\n",
            "7       32.0   0.000  32.0  0.1000         2.0 -1.5056 -1.4599\n",
            "8       32.0   0.000  64.0  0.0001         0.0 -2.1956 -2.1300\n",
            "9       32.0   0.000  64.0  0.0010         2.0 -2.1706 -2.1055\n",
            "10      32.0   0.000  64.0  0.0100         2.0 -2.0448 -1.9824\n",
            "11      32.0   0.000  64.0  0.1000         2.0 -1.0606 -1.0272\n",
            "12      32.0   0.001  16.0  0.0001         0.0 -2.1956 -2.1300\n",
            "13      32.0   0.001  16.0  0.0010         2.0 -2.0911 -2.0283\n",
            "14      32.0   0.001  16.0  0.0100         0.0 -2.1948 -2.1293\n",
            "15      32.0   0.001  16.0  0.1000         2.0 -1.7454 -1.6927\n",
            "16      32.0   0.001  32.0  0.0001         0.0 -2.1956 -2.1300\n",
            "17      32.0   0.001  32.0  0.0010         2.0 -2.1464 -2.0823\n",
            "18      32.0   0.001  32.0  0.0100         2.0 -2.0964 -2.0334\n",
            "19      32.0   0.001  32.0  0.1000         0.0 -2.1952 -2.1296\n",
            "20      32.0   0.001  64.0  0.0001         2.0 -2.1928 -2.1276\n",
            "21      32.0   0.001  64.0  0.0010         2.0 -2.1061 -2.0429\n",
            "22      32.0   0.001  64.0  0.0100         2.0 -1.9706 -1.9107\n",
            "23      32.0   0.001  64.0  0.1000         2.0 -1.0395 -1.0073\n",
            "24      32.0   0.010  16.0  0.0001         2.0 -2.1708 -2.1060\n",
            "25      32.0   0.010  16.0  0.0010         2.0 -2.1799 -2.1150\n",
            "26      32.0   0.010  16.0  0.0100         2.0 -2.0714 -2.0092\n",
            "27      32.0   0.010  16.0  0.1000         0.0 -2.1955 -2.1299\n",
            "28      32.0   0.010  32.0  0.0001         0.0 -2.1953 -2.1297\n",
            "29      32.0   0.010  32.0  0.0010         2.0 -2.1306 -2.0668\n",
            "30      32.0   0.010  32.0  0.0100         2.0 -2.0374 -1.9762\n",
            "31      32.0   0.010  32.0  0.1000         2.0 -1.6297 -1.5805\n",
            "32      32.0   0.010  64.0  0.0001         2.0 -2.1198 -2.0563\n",
            "33      32.0   0.010  64.0  0.0010         2.0 -2.1475 -2.0832\n",
            "34      32.0   0.010  64.0  0.0100         0.0 -2.1956 -2.1300\n",
            "35      32.0   0.010  64.0  0.1000         0.0 -2.1956 -2.1300\n",
            "36      64.0   0.000  16.0  0.0001         2.0 -2.2043 -2.1510\n",
            "37      64.0   0.000  16.0  0.0010         2.0 -2.1830 -2.1302\n",
            "38      64.0   0.000  16.0  0.0100         2.0 -2.1548 -2.1024\n",
            "39      64.0   0.000  16.0  0.1000         2.0 -1.8654 -1.8204\n",
            "40      64.0   0.000  32.0  0.0001         2.0 -2.1697 -2.1173\n",
            "41      64.0   0.000  32.0  0.0010         2.0 -2.1623 -2.1100\n",
            "42      64.0   0.000  32.0  0.0100         2.0 -2.1384 -2.0864\n",
            "43      64.0   0.000  32.0  0.1000         0.0 -2.2226 -2.1689\n",
            "44      64.0   0.000  64.0  0.0001         2.0 -2.1793 -2.1268\n",
            "45      64.0   0.000  64.0  0.0010         2.0 -2.1897 -2.1366\n",
            "46      64.0   0.000  64.0  0.0100         2.0 -2.0502 -2.0002\n",
            "47      64.0   0.000  64.0  0.1000         2.0 -1.0985 -1.0717\n",
            "48      64.0   0.001  16.0  0.0001         2.0 -2.1933 -2.1402\n",
            "49      64.0   0.001  16.0  0.0010         0.0 -2.2226 -2.1689\n",
            "50      64.0   0.001  16.0  0.0100         0.0 -2.2226 -2.1689\n",
            "51      64.0   0.001  16.0  0.1000         2.0 -1.8812 -1.8359\n",
            "52      64.0   0.001  32.0  0.0001         0.0 -2.2226 -2.1689\n",
            "53      64.0   0.001  32.0  0.0010         2.0 -2.1432 -2.0916\n",
            "54      64.0   0.001  32.0  0.0100         0.0 -2.2226 -2.1689\n",
            "55      64.0   0.001  32.0  0.1000         2.0 -1.5256 -1.4885\n",
            "56      64.0   0.001  64.0  0.0001         2.0 -2.2219 -2.1683\n",
            "57      64.0   0.001  64.0  0.0010         2.0 -2.1548 -2.1025\n",
            "58      64.0   0.001  64.0  0.0100         0.0 -2.2226 -2.1689\n",
            "59      64.0   0.001  64.0  0.1000         2.0 -1.0897 -1.0633\n",
            "60      64.0   0.010  16.0  0.0001         2.0 -2.1581 -2.1062\n",
            "61      64.0   0.010  16.0  0.0010         0.0 -2.2226 -2.1689\n",
            "62      64.0   0.010  16.0  0.0100         2.0 -2.1625 -2.1103\n",
            "63      64.0   0.010  16.0  0.1000         2.0 -1.7769 -1.7342\n",
            "64      64.0   0.010  32.0  0.0001         2.0 -2.1997 -2.1464\n",
            "65      64.0   0.010  32.0  0.0010         2.0 -2.1807 -2.1279\n",
            "66      64.0   0.010  32.0  0.0100         0.0 -2.2226 -2.1689\n",
            "67      64.0   0.010  32.0  0.1000         2.0 -1.5296 -1.4929\n",
            "68      64.0   0.010  64.0  0.0001         2.0 -2.1861 -2.1335\n",
            "69      64.0   0.010  64.0  0.0010         2.0 -2.1564 -2.1043\n",
            "70      64.0   0.010  64.0  0.0100         0.0 -2.2226 -2.1689\n",
            "71      64.0   0.010  64.0  0.1000         0.0 -2.2226 -2.1689\n",
            "72     128.0   0.000  16.0  0.0001         2.0 -2.4569 -2.4320\n",
            "73     128.0   0.000  16.0  0.0010         2.0 -2.5020 -2.4764\n",
            "74     128.0   0.000  16.0  0.0100         2.0 -2.4616 -2.4364\n",
            "75     128.0   0.000  16.0  0.1000         2.0 -2.0312 -2.0118\n",
            "76     128.0   0.000  32.0  0.0001         2.0 -2.5160 -2.4903\n",
            "77     128.0   0.000  32.0  0.0010         2.0 -2.5018 -2.4762\n",
            "78     128.0   0.000  32.0  0.0100         0.0 -2.5169 -2.4912\n",
            "79     128.0   0.000  32.0  0.1000         0.0 -2.5169 -2.4912\n",
            "80     128.0   0.000  64.0  0.0001         2.0 -2.4707 -2.4455\n",
            "81     128.0   0.000  64.0  0.0010         2.0 -2.4809 -2.4554\n",
            "82     128.0   0.000  64.0  0.0100         2.0 -2.3432 -2.3194\n",
            "83     128.0   0.000  64.0  0.1000         2.0 -1.2046 -1.1952\n",
            "84     128.0   0.001  16.0  0.0001         0.0 -2.5169 -2.4912\n",
            "85     128.0   0.001  16.0  0.0010         2.0 -2.4357 -2.4110\n",
            "86     128.0   0.001  16.0  0.0100         0.0 -2.5169 -2.4912\n",
            "87     128.0   0.001  16.0  0.1000         0.0 -2.5169 -2.4912\n",
            "88     128.0   0.001  32.0  0.0001         2.0 -2.4816 -2.4565\n",
            "89     128.0   0.001  32.0  0.0010         0.0 -2.5169 -2.4912\n",
            "90     128.0   0.001  32.0  0.0100         2.0 -2.3196 -2.2963\n",
            "91     128.0   0.001  32.0  0.1000         0.0 -2.5169 -2.4912\n",
            "92     128.0   0.001  64.0  0.0001         2.0 -2.3951 -2.3710\n",
            "93     128.0   0.001  64.0  0.0010         2.0 -2.4461 -2.4213\n",
            "94     128.0   0.001  64.0  0.0100         2.0 -2.3516 -2.3281\n",
            "95     128.0   0.001  64.0  0.1000         2.0 -1.1764 -1.1667\n",
            "96     128.0   0.010  16.0  0.0001         2.0 -2.4631 -2.4381\n",
            "97     128.0   0.010  16.0  0.0010         0.0 -2.5169 -2.4912\n",
            "98     128.0   0.010  16.0  0.0100         0.0 -2.5169 -2.4912\n",
            "99     128.0   0.010  16.0  0.1000         0.0 -2.5169 -2.4912\n",
            "100    128.0   0.010  32.0  0.0001         2.0 -2.5162 -2.4905\n",
            "101    128.0   0.010  32.0  0.0010         2.0 -2.5088 -2.4834\n",
            "102    128.0   0.010  32.0  0.0100         2.0 -2.3811 -2.3572\n",
            "103    128.0   0.010  32.0  0.1000         2.0 -1.8168 -1.8001\n",
            "104    128.0   0.010  64.0  0.0001         0.0 -2.5169 -2.4912\n",
            "105    128.0   0.010  64.0  0.0010         2.0 -2.4344 -2.4098\n",
            "106    128.0   0.010  64.0  0.0100         0.0 -2.5169 -2.4912\n",
            "107    128.0   0.010  64.0  0.1000         2.0 -1.2202 -1.2105\n"
          ]
        }
      ],
      "source": [
        "# main\n",
        "df_result = pd.DataFrame({'n_train':[], 'smooth':[], 'size':[], 'lr':[], 'best_epoch':[], 'R2_qrh':[], 'R2_msa':[]})\n",
        "\n",
        "for n_train in [32, 64, 128]:\n",
        "    for _smooth in [0, 0.001, 0.01]:\n",
        "        for h in [16, 32, 64]:\n",
        "            for _lr in [0.0001, 0.001, 0.01, 0.1]:\n",
        "\n",
        "                # Read data\n",
        "                df = pd.read_csv('C:/Users/tln229/Downloads/Python/1. Building/data/HVAC_B90_102_exp_10m_20210424.csv')\n",
        "                qrh = np.array(df['htg_valve_position']).reshape(-1,1)\n",
        "                msa = np.array(df['airflow_current']).reshape(-1,1)\n",
        "\n",
        "                # LEAST SQUARE\n",
        "                ones = np.ones(msa.shape)\n",
        "                A = np.concatenate((qrh, ones), axis=1)\n",
        "                b = np.copy(msa)\n",
        "                p = np.linalg.lstsq(A, b, rcond=None)[0]\n",
        "\n",
        "                # Create network\n",
        "                device = torch.device(\"cpu\")\n",
        "                net = Net(h).to(device)\n",
        "\n",
        "                # Create Dataset and DataLoader objects\n",
        "                src_file = 'C:/Users/tln229/Downloads/Python/1. Building/data/HVAC_B90_102_exp_10m_20210424.csv'\n",
        "                train_ds = Data(src_file, start=0, end=n_train)\n",
        "                test_ds  = Data(src_file, start=n_train, end=1600)\n",
        "\n",
        "                # train\n",
        "                R2_qrh, R2_msa = train(net, p, train_ds, test_ds, lr=_lr, min_epochs=500, max_epochs=100000, patience=300, smooth=_smooth)\n",
        "\n",
        "                # results\n",
        "                # print('n train = %3d \\t smooth = %6.4f \\t layer size = %2d \\t lr = %6.4f \\t best_epoch = %5d \\t best_R2_qrh = %7.5f \\t best_R2_msa = %7.5f'\n",
        "                #     % (n_train, _smooth, h, _lr, np.argmax(R2_qrh), np.max(R2_qrh), np.max(R2_msa)))\n",
        "                df_result.loc[len(df_result)] = [n_train, _smooth, h, _lr, np.argmax(R2_qrh), np.max(R2_qrh), np.max(R2_msa)]\n",
        "\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 4,\n",
        "                       ):\n",
        "    print(df_result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "912d6611990680b3d240e982c9d50f3da4c776707cfd42695cf7d82c88d80956"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
